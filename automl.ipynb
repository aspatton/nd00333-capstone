{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall requests urllib3 -y"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests==2.29 urllib3==1.26"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import csv\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import pkg_resources\n",
        "import azureml\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.core import Model\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.51.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1711076936992
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "exp = Experiment(workspace=ws, name=\"udacity-capstone-automl\")\n",
        "\n",
        "#print('Workspace name: ' + ws.name, \n",
        "#      'Azure region: ' + ws.location, \n",
        "#      'Subscription id: ' + ws.subscription_id, \n",
        "#      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = exp.start_logging()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1711077013057
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key = \"penguins\"\n",
        "description_text = \"Penguin Data from Kaggle for Udacity Course Capstone project\"\n",
        "\n",
        "ds = ws.datasets[key] \n",
        "\n",
        "\n",
        "df = ds.to_pandas_dataframe()\n",
        "df.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "       species  island culmen_length_mm culmen_depth_mm flipper_length_mm  \\\ncount      344     344              344             344               344   \nunique       3       3              165              81                56   \ntop     Adelie  Biscoe             41.1              17               190   \nfreq       152     168                7              12                22   \n\n       body_mass_g   sex  \ncount          344   344  \nunique          95     4  \ntop           3800  MALE  \nfreq            12   168  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>species</th>\n      <th>island</th>\n      <th>culmen_length_mm</th>\n      <th>culmen_depth_mm</th>\n      <th>flipper_length_mm</th>\n      <th>body_mass_g</th>\n      <th>sex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>344</td>\n      <td>344</td>\n      <td>344</td>\n      <td>344</td>\n      <td>344</td>\n      <td>344</td>\n      <td>344</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>3</td>\n      <td>3</td>\n      <td>165</td>\n      <td>81</td>\n      <td>56</td>\n      <td>95</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Adelie</td>\n      <td>Biscoe</td>\n      <td>41.1</td>\n      <td>17</td>\n      <td>190</td>\n      <td>3800</td>\n      <td>MALE</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>152</td>\n      <td>168</td>\n      <td>7</td>\n      <td>12</td>\n      <td>22</td>\n      <td>12</td>\n      <td>168</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711077025149
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"capstone-compute\"\n",
        "\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4, )\n",
        "    cpu_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n\nRunning\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711077033640
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from azureml.core import ScriptRunConfig\n",
        "#from azureml.widgets import RunDetails\n",
        "\n",
        "#ws = Workspace.from_config()\n",
        "#experiment = Experiment(workspace=ws, name='day1-experiment-hello')\n",
        "\n",
        "#config = ScriptRunConfig(source_directory='./', script='hello.py', compute_target='capstone-compute')\n",
        "\n",
        "#run = experiment.submit(config)\n",
        "#RunDetails(run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711068040883
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#project_folder = './pipeline-project'\n",
        "\n",
        "automl_config = AutoMLConfig(compute_target=cpu_cluster,\n",
        "                             task = \"classification\",\n",
        "                             training_data=ds,\n",
        "                             label_column_name=\"species\",   \n",
        "                             path = './outputs',\n",
        "                             enable_early_stopping= True,\n",
        "                             featurization= 'auto',\n",
        "                             debug_log = \"automl_errors.log\",\n",
        "                             experiment_timeout_minutes=15,\n",
        "                             max_concurrent_iterations=4,\n",
        "                             primary_metric='AUC_weighted'\n",
        "                            )"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1711077039570
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "remote_run = exp.submit(automl_config, show_output=True)\n",
        "remote_run.wait_for_completion()\n",
        "\n",
        "remote_run"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submitting remote run.\nNo run_configuration provided, running on capstone-compute with default configuration\nRunning on remote compute: capstone-compute\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>udacity-capstone-automl</td><td>AutoML_c8f7767a-a6ba-44cf-b7d8-1e4a0516a2cc</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_c8f7767a-a6ba-44cf-b7d8-1e4a0516a2cc?wsid=/subscriptions/a022d83d-6229-4b5e-b039-b680692436b5/resourcegroups/aspatton01-rg/workspaces/udacity_ml_azure_capstone&amp;tid=41b3409a-40cf-45e8-8201-ddfa1984ab3d\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nCurrent status: FeaturesGeneration. Generating features for the dataset.\nCurrent status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\nCurrent status: ModelSelection. Beginning model selection.\n\n********************************************************************************************\nDATA GUARDRAILS: \n\nTYPE:         Cross validation\nSTATUS:       DONE\nDESCRIPTION:  In order to accurately evaluate the model(s) trained by AutoML, we leverage a dataset that the model is not trained on. Hence, if the user doesn't provide an explicit validation dataset, a part of the training dataset is used to achieve this. For smaller datasets (fewer than 20,000 samples), cross-validation is leveraged, else a single hold-out set is split from the training data to serve as the validation dataset. Hence, for your input data we leverage cross-validation with 10 folds, if the number of training samples are fewer than 1000, and 3 folds in all other cases.\n              Learn more about cross validation: https://aka.ms/AutomatedMLCrossValidation\nDETAILS:      \n+------------------------------+\n|Number of folds               |\n+==============================+\n|10                            |\n+------------------------------+\n\n********************************************************************************************\n\nTYPE:         Class balancing detection\nSTATUS:       PASSED\nDESCRIPTION:  Your inputs were analyzed, and all classes are balanced in your training data.\n              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n\n********************************************************************************************\n\nTYPE:         Missing feature values imputation\nSTATUS:       PASSED\nDESCRIPTION:  No feature missing values were detected in the training data.\n              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n\n********************************************************************************************\n\nTYPE:         High cardinality feature detection\nSTATUS:       PASSED\nDESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n\n********************************************************************************************\n\n********************************************************************************************\nITER: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************\n\n ITER   PIPELINE                                       DURATION            METRIC      BEST\n    0   MaxAbsScaler LightGBM                          0:00:21             0.8284    0.8284\n    1   MaxAbsScaler XGBoostClassifier                 0:00:22             0.9115    0.9115\n    5   SparseNormalizer XGBoostClassifier             0:00:19             0.9099    0.9115\n    2   MaxAbsScaler ExtremeRandomTrees                0:00:18             0.8464    0.9115\n    6   SparseNormalizer RandomForest                  0:00:23             0.9161    0.9161\n    3   MaxAbsScaler RandomForest                      0:00:18             0.8540    0.9161\n    7   StandardScalerWrapper XGBoostClassifier        0:00:18             0.9195    0.9195\n    8   SparseNormalizer XGBoostClassifier             0:00:18             0.9068    0.9195\n   10   SparseNormalizer LightGBM                      0:00:17             0.8307    0.9195\n   11   MaxAbsScaler ExtremeRandomTrees                0:00:28             0.9271    0.9271\n    4   StandardScalerWrapper LightGBM                 0:00:18             0.8247    0.9271\n    9   MaxAbsScaler RandomForest                      0:00:18             0.6477    0.9271\n   12   StandardScalerWrapper XGBoostClassifier        0:00:17             0.9047    0.9271\n   13   StandardScalerWrapper ExtremeRandomTrees       0:00:18             0.9084    0.9271\n   14   StandardScalerWrapper RandomForest             0:00:20             0.9434    0.9434\n   15   MaxAbsScaler LightGBM                          0:00:22             0.8933    0.9434\n   16   MaxAbsScaler LogisticRegression                0:00:18             0.9342    0.9434\n   17   StandardScalerWrapper ExtremeRandomTrees       0:00:26             0.8720    0.9434\n   18   StandardScalerWrapper XGBoostClassifier        0:00:14             0.9023    0.9434\n   19   MaxAbsScaler ExtremeRandomTrees                0:00:16             0.9202    0.9434\n   20   MaxAbsScaler LogisticRegression                0:00:39             0.9296    0.9434\n   21   StandardScalerWrapper XGBoostClassifier        0:00:40             0.8958    0.9434\n   22   StandardScalerWrapper XGBoostClassifier        0:00:35             0.9152    0.9434\n   23   MaxAbsScaler RandomForest                      0:00:45             0.8064    0.9434\n   24   SparseNormalizer XGBoostClassifier             0:00:46             0.8288    0.9434\n   26   TruncatedSVDWrapper XGBoostClassifier          0:00:54             0.9173    0.9434\n   27   StandardScalerWrapper LightGBM                 0:00:36             0.8507    0.9434\n   28   MaxAbsScaler LightGBM                          0:00:35             0.8419    0.9434\n   29   MaxAbsScaler LightGBM                          0:00:34             0.8581    0.9434\n   25   TruncatedSVDWrapper RandomForest               0:02:31             0.8353    0.9434\n   31   MaxAbsScaler LogisticRegression                0:00:38             0.9396    0.9434\n   32   MaxAbsScaler LogisticRegression                0:00:40             0.9345    0.9434\n   30   TruncatedSVDWrapper RandomForest               0:01:21             0.8671    0.9434\n   33   StandardScalerWrapper LogisticRegression       0:00:38             0.9331    0.9434\n   34   StandardScalerWrapper LogisticRegression       0:00:38             0.9385    0.9434\n   35   SparseNormalizer RandomForest                  0:01:03             0.9063    0.9434\n   36    VotingEnsemble                                0:01:06             0.9570    0.9570\n   37    StackEnsemble                                 0:01:06             0.9551    0.9570\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "{'runId': 'AutoML_c8f7767a-a6ba-44cf-b7d8-1e4a0516a2cc',\n 'target': 'capstone-compute',\n 'status': 'Completed',\n 'startTimeUtc': '2024-03-22T03:11:06.389894Z',\n 'endTimeUtc': '2024-03-22T03:23:19.789378Z',\n 'services': {},\n 'warnings': [{'source': 'JasmineService',\n   'message': 'No scores improved over last 10 iterations, so experiment stopped early. This early stopping behavior can be disabled by setting enable_early_stopping = False in AutoMLConfig for notebook/python SDK runs.'}],\n 'properties': {'num_iterations': '1000',\n  'training_type': 'TrainFull',\n  'acquisition_function': 'EI',\n  'primary_metric': 'AUC_weighted',\n  'train_split': '0',\n  'acquisition_parameter': '0',\n  'num_cross_validation': None,\n  'target': 'capstone-compute',\n  'AMLSettingsJsonString': '{\"path\":null,\"name\":\"udacity-capstone-automl\",\"subscription_id\":\"a022d83d-6229-4b5e-b039-b680692436b5\",\"resource_group\":\"aspatton01-rg\",\"workspace_name\":\"udacity_ml_azure_capstone\",\"region\":\"eastus2\",\"compute_target\":\"capstone-compute\",\"spark_service\":null,\"azure_service\":\"remote\",\"many_models\":false,\"pipeline_fetch_max_batch_size\":1,\"enable_batch_run\":true,\"enable_parallel_run\":false,\"num_procs\":null,\"enable_run_restructure\":false,\"start_auxiliary_runs_before_parent_complete\":false,\"enable_code_generation\":true,\"iterations\":1000,\"primary_metric\":\"AUC_weighted\",\"task_type\":\"classification\",\"positive_label\":null,\"data_script\":null,\"test_size\":0.0,\"test_include_predictions_only\":false,\"validation_size\":0.0,\"n_cross_validations\":null,\"y_min\":null,\"y_max\":null,\"num_classes\":null,\"featurization\":\"auto\",\"_ignore_package_version_incompatibilities\":false,\"is_timeseries\":false,\"max_cores_per_iteration\":1,\"max_concurrent_iterations\":4,\"iteration_timeout_minutes\":null,\"mem_in_mb\":null,\"enforce_time_on_windows\":false,\"experiment_timeout_minutes\":15,\"experiment_exit_score\":null,\"partition_column_names\":null,\"whitelist_models\":null,\"blacklist_algos\":[\"TensorFlowLinearClassifier\",\"TensorFlowDNN\"],\"supported_models\":[\"MultinomialNaiveBayes\",\"SGD\",\"LightGBM\",\"TensorFlowDNN\",\"GradientBoosting\",\"BernoulliNaiveBayes\",\"KNN\",\"RandomForest\",\"ExtremeRandomTrees\",\"TensorFlowLinearClassifier\",\"SVM\",\"TabnetClassifier\",\"XGBoostClassifier\",\"LinearSVM\",\"AveragedPerceptronClassifier\",\"DecisionTree\",\"LogisticRegression\"],\"private_models\":[],\"auto_blacklist\":true,\"blacklist_samples_reached\":false,\"exclude_nan_labels\":true,\"verbosity\":20,\"_debug_log\":\"azureml_automl.log\",\"show_warnings\":false,\"model_explainability\":true,\"service_url\":null,\"sdk_url\":null,\"sdk_packages\":null,\"enable_onnx_compatible_models\":false,\"enable_split_onnx_featurizer_estimator_models\":false,\"vm_type\":\"Standard_D4s_v3\",\"telemetry_verbosity\":20,\"send_telemetry\":true,\"enable_dnn\":false,\"scenario\":\"AutoML\",\"environment_label\":null,\"save_mlflow\":false,\"enable_categorical_indicators\":false,\"force_text_dnn\":false,\"enable_feature_sweeping\":true,\"enable_early_stopping\":true,\"early_stopping_n_iters\":10,\"arguments\":null,\"dataset_id\":\"b8d5f66a-9d99-4f9b-b6b8-62f8873e4bf2\",\"hyperdrive_config\":null,\"validation_dataset_id\":null,\"run_source\":null,\"metrics\":null,\"enable_metric_confidence\":false,\"enable_ensembling\":true,\"enable_stack_ensembling\":true,\"ensemble_iterations\":15,\"enable_tf\":false,\"enable_subsampling\":null,\"subsample_seed\":null,\"enable_nimbusml\":false,\"enable_streaming\":false,\"force_streaming\":false,\"track_child_runs\":true,\"n_best_runs\":1,\"allowed_private_models\":[],\"label_column_name\":\"species\",\"weight_column_name\":null,\"cv_split_column_names\":null,\"enable_local_managed\":false,\"_local_managed_run_id\":null,\"cost_mode\":1,\"lag_length\":0,\"metric_operation\":\"maximize\",\"preprocess\":true}',\n  'DataPrepJsonString': '{\\\\\"training_data\\\\\": {\\\\\"datasetId\\\\\": \\\\\"b8d5f66a-9d99-4f9b-b6b8-62f8873e4bf2\\\\\"}, \\\\\"datasets\\\\\": 0}',\n  'EnableSubsampling': None,\n  'runTemplate': 'AutoML',\n  'azureml.runsource': 'automl',\n  'display_task_type': 'classification',\n  'dependencies_versions': '{\"azureml-dataprep-native\": \"38.0.0\", \"azureml-dataprep\": \"4.10.8\", \"azureml-dataprep-rslex\": \"2.17.12\", \"azureml-train-automl-runtime\": \"1.51.0.post2\", \"azureml-train-automl-client\": \"1.51.0.post1\", \"azureml-training-tabular\": \"1.51.0.post1\", \"azureml-automl-runtime\": \"1.51.0.post1\", \"azureml-automl-core\": \"1.51.0.post1\", \"azureml-mlflow\": \"1.51.0\", \"azureml-datadrift\": \"1.51.0\", \"azureml-pipeline\": \"1.51.0\", \"azureml-contrib-dataset\": \"1.51.0\", \"azureml-contrib-notebook\": \"1.51.0\", \"azureml-accel-models\": \"1.51.0\", \"azureml-automl-dnn-nlp\": \"1.51.0\", \"azureml-pipeline-core\": \"1.51.0\", \"azureml-responsibleai\": \"1.51.0\", \"azureml-contrib-automl-pipeline-steps\": \"1.51.0\", \"azureml-pipeline-steps\": \"1.51.0\", \"azureml-core\": \"1.51.0\", \"azureml-contrib-reinforcementlearning\": \"1.51.0\", \"azureml-contrib-server\": \"1.51.0\", \"azureml-opendatasets\": \"1.51.0\", \"azureml-contrib-services\": \"1.51.0\", \"azureml-telemetry\": \"1.51.0\", \"azureml-train-restclients-hyperdrive\": \"1.51.0\", \"azureml-interpret\": \"1.51.0\", \"azureml-train-core\": \"1.51.0\", \"azureml-tensorboard\": \"1.51.0\", \"azureml-train\": \"1.51.0\", \"azureml-contrib-pipeline-steps\": \"1.51.0\", \"azureml-explain-model\": \"1.51.0\", \"azureml-cli-common\": \"1.51.0\", \"azureml-widgets\": \"1.51.0\", \"azureml-train-automl\": \"1.51.0\", \"azureml-defaults\": \"1.51.0\", \"azureml-contrib-fairness\": \"1.51.0\", \"azureml-sdk\": \"1.51.0\", \"azureml-dataset-runtime\": \"1.51.0\", \"azureml-inference-server-http\": \"0.8.4\"}',\n  '_aml_system_scenario_identification': 'Remote.Parent',\n  'ClientType': 'SDK',\n  'PlatformVersion': 'DPV1',\n  'environment_cpu_name': 'AzureML-AutoML',\n  'environment_cpu_label': 'scikit-upgrade2',\n  'environment_gpu_name': 'AzureML-AutoML-GPU',\n  'environment_gpu_label': 'scikit-upgrade2',\n  'root_attribution': 'automl',\n  'attribution': 'AutoML',\n  'Orchestrator': 'AutoML',\n  'CancelUri': 'https://eastus2.api.azureml.ms/jasmine/v1.0/subscriptions/a022d83d-6229-4b5e-b039-b680692436b5/resourceGroups/aspatton01-rg/providers/Microsoft.MachineLearningServices/workspaces/udacity_ml_azure_capstone/experimentids/f7b438bc-e935-45ed-b6d5-f9df98e14299/cancel/AutoML_c8f7767a-a6ba-44cf-b7d8-1e4a0516a2cc',\n  'ClientSdkVersion': None,\n  'snapshotId': '00000000-0000-0000-0000-000000000000',\n  'SetupRunId': 'AutoML_c8f7767a-a6ba-44cf-b7d8-1e4a0516a2cc_setup',\n  'SetupRunContainerId': 'dcid.AutoML_c8f7767a-a6ba-44cf-b7d8-1e4a0516a2cc_setup',\n  'FeaturizationRunJsonPath': 'featurizer_container.json',\n  'FeaturizationRunId': 'AutoML_c8f7767a-a6ba-44cf-b7d8-1e4a0516a2cc_featurize',\n  'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": true, \"subsampling\": false, \"has_extra_col\": true, \"dataset_classes\": 3, \"dataset_features\": 295, \"dataset_samples\": 344, \"single_frequency_class_detected\": false}',\n  'ModelExplainRunId': 'AutoML_c8f7767a-a6ba-44cf-b7d8-1e4a0516a2cc_ModelExplain'},\n 'inputDatasets': [{'dataset': {'id': 'b8d5f66a-9d99-4f9b-b6b8-62f8873e4bf2'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}],\n 'outputDatasets': [],\n 'logFiles': {},\n 'submittedBy': 'Tony Patton'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711077822664
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get best run and model\n",
        "best_run, fitted_model = remote_run.get_output()\n",
        "\n",
        "print(fitted_model) #To print\n",
        "\n",
        "import joblib  \n",
        "\n",
        "#joblib.dump(fitted_model, \"automl_fitted.pkl\")\n",
        "#joblib.dump(best_run, \"automl_bestrun.pkl\")\n",
        "# Print the best run\n",
        "print(best_run)\n",
        "\n",
        "# Get all metrics of the best run\n",
        "#best_run_metrics = best_run.get_metrics()\n",
        "\n",
        "# Print all metrics of the best run\n",
        "#for metric_name in best_run_metrics:\n",
        "#    metric = best_run_metrics[metric_name]\n",
        "#    print(metric_name, metric)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:root:The version of the SDK does not match the version the model was trained on.\nWARNING:root:The consistency in the result may not be guaranteed.\nWARNING:root:Package:azureml-automl-core, training version:1.52.0.post1, current version:1.51.0.post1\nPackage:azureml-automl-runtime, training version:1.52.0.post1, current version:1.51.0.post1\nPackage:azureml-core, training version:1.52.0, current version:1.51.0\nPackage:azureml-dataprep, training version:4.11.4, current version:4.10.8\nPackage:azureml-dataprep-rslex, training version:2.18.4, current version:2.17.12\nPackage:azureml-dataset-runtime, training version:1.52.0, current version:1.51.0\nPackage:azureml-defaults, training version:1.52.0, current version:1.51.0\nPackage:azureml-interpret, training version:1.52.0, current version:1.51.0\nPackage:azureml-mlflow, training version:1.52.0, current version:1.51.0\nPackage:azureml-pipeline-core, training version:1.52.0, current version:1.51.0\nPackage:azureml-responsibleai, training version:1.52.0, current version:1.51.0\nPackage:azureml-telemetry, training version:1.52.0, current version:1.51.0\nPackage:azureml-train-automl-client, training version:1.52.0, current version:1.51.0.post1\nPackage:azureml-train-automl-runtime, training version:1.52.0, current version:1.51.0.post2\nPackage:azureml-train-core, training version:1.52.0, current version:1.51.0\nPackage:azureml-train-restclients-hyperdrive, training version:1.52.0, current version:1.51.0\nPackage:azureml-training-tabular, training version:1.52.0, current version:1.51.0.post1\nWARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline(memory=None,\n         steps=[('datatransformer',\n                 DataTransformer(enable_dnn=False, enable_feature_sweeping=True, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=True, is_onnx_compatible=False, observer=None, task='classification', working_dir='/mnt/batch/tasks/shared/LS_root/mount...\n                 PreFittedSoftVotingClassifier(classification_labels=array([0, 1, 2]), estimators=[('14', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=False, with_std=False)), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features='auto', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False))], verbose=False)), ('31', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('logisticregression', LogisticRegression(C=24.420530945486497, class_weight='balanced', dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='multinomial', n_jobs=1, penalty='l2', random_state=None, solver='saga', tol=0.0001, verbose=0, warm_start=False))], verbose=False)), ('34', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=False, with_std=True)), ('logisticregression', LogisticRegression(C=0.2682695795279725, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l1', random_state=None, solver='saga', tol=0.0001, verbose=0, warm_start=False))], verbose=False)), ('32', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('logisticregression', LogisticRegression(C=6866.488450042998, class_weight='balanced', dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=None, solver='saga', tol=0.0001, verbose=0, warm_start=False))], verbose=False)), ('16', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('logisticregression', LogisticRegression(C=4714.8663634573895, class_weight='balanced', dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='multinomial', n_jobs=1, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))], verbose=False)), ('33', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=False, with_std=True)), ('logisticregression', LogisticRegression(C=3237.45754281764, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=None, solver='saga', tol=0.0001, verbose=0, warm_start=False))], verbose=False)), ('13', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=False, with_std=False)), ('extratreesclassifier', ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None, criterion='entropy', max_depth=None, max_features=0.05, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.01, min_samples_split=0.01, min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False))], verbose=False))], flatten_transform=None, weights=[0.3333333333333333, 0.08333333333333333, 0.16666666666666666, 0.08333333333333333, 0.08333333333333333, 0.16666666666666666, 0.08333333333333333]))],\n         verbose=False)\nY_transformer(['LabelEncoder', LabelEncoder()])\nRun(Experiment: udacity-capstone-automl,\nId: AutoML_c8f7767a-a6ba-44cf-b7d8-1e4a0516a2cc_36,\nType: azureml.scriptrun,\nStatus: Completed)\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711078073595
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all metrics of the best run\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "\n",
        "# Print all metrics of the best run\n",
        "for metric_name in best_run_metrics:\n",
        "    metric = best_run_metrics[metric_name]\n",
        "    print(metric_name, metric)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "precision_score_weighted 0.842273527784897\nrecall_score_micro 0.8192436974789915\naverage_precision_score_weighted 0.9273110803960813\naverage_precision_score_micro 0.9273186816134015\naverage_precision_score_macro 0.9065395959411985\nAUC_weighted 0.9570146646621946\nnorm_macro_recall 0.7205823192974894\nrecall_score_macro 0.8137215461983264\nf1_score_micro 0.8192436974789915\nAUC_micro 0.9597639644092931\nf1_score_weighted 0.8176583122759592\naccuracy 0.8192436974789915\nprecision_score_macro 0.8075436654848419\nbalanced_accuracy 0.8137215461983264\nweighted_accuracy 0.8157358614669917\nrecall_score_weighted 0.8192436974789915\nlog_loss 0.38528529364020503\nAUC_macro 0.9581084739009882\nmatthews_correlation 0.7284852684118489\nprecision_score_micro 0.8192436974789915\nf1_score_macro 0.796297554414569\naccuracy_table aml://artifactId/ExperimentRun/dcid.AutoML_c8f7767a-a6ba-44cf-b7d8-1e4a0516a2cc_36/accuracy_table\nconfusion_matrix aml://artifactId/ExperimentRun/dcid.AutoML_c8f7767a-a6ba-44cf-b7d8-1e4a0516a2cc_36/confusion_matrix\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711078125124
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print detailed parameters of the fitted model\n",
        "def print_model(model, prefix=\"\"):\n",
        "    for step in model.steps:\n",
        "        print(prefix + step[0])\n",
        "        if hasattr(step[1], 'estimators') and hasattr(step[1], 'weights'):\n",
        "            print({'estimators': list(\n",
        "                e[0] for e in step[1].estimators), 'weights': step[1].weights})\n",
        "            print()\n",
        "            for estimator in step[1].estimators:\n",
        "                print_model(estimator[1], estimator[0] + ' - ')\n",
        "        else:\n",
        "            print(step[1].get_params())\n",
        "            print()\n",
        "\n",
        "print_model(fitted_model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "datatransformer\n{'task': 'classification', 'is_onnx_compatible': False, 'enable_feature_sweeping': True, 'enable_dnn': False, 'force_text_dnn': False, 'feature_sweeping_timeout': 86400, 'featurization_config': None, 'is_cross_validation': True, 'feature_sweeping_config': {}, 'observer': None, 'working_dir': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/capstone-compute/code/Users/aspatton01/nd00333-capstone'}\n\nprefittedsoftvotingclassifier\n{'estimators': ['14', '31', '34', '32', '16', '33', '13'], 'weights': [0.3333333333333333, 0.08333333333333333, 0.16666666666666666, 0.08333333333333333, 0.08333333333333333, 0.16666666666666666, 0.08333333333333333]}\n\n14 - standardscalerwrapper\n{'module_name': 'sklearn.preprocessing._data', 'class_name': 'StandardScaler', 'copy': True, 'with_mean': False, 'with_std': False}\n\n14 - randomforestclassifier\n{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n\n31 - maxabsscaler\n{'copy': True}\n\n31 - logisticregression\n{'C': 24.420530945486497, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': 1, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n\n34 - standardscalerwrapper\n{'module_name': 'sklearn.preprocessing._data', 'class_name': 'StandardScaler', 'copy': True, 'with_mean': False, 'with_std': True}\n\n34 - logisticregression\n{'C': 0.2682695795279725, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'ovr', 'n_jobs': 1, 'penalty': 'l1', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n\n32 - maxabsscaler\n{'copy': True}\n\n32 - logisticregression\n{'C': 6866.488450042998, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'ovr', 'n_jobs': 1, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n\n16 - maxabsscaler\n{'copy': True}\n\n16 - logisticregression\n{'C': 4714.8663634573895, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': 1, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n\n33 - standardscalerwrapper\n{'module_name': 'sklearn.preprocessing._data', 'class_name': 'StandardScaler', 'copy': True, 'with_mean': False, 'with_std': True}\n\n33 - logisticregression\n{'C': 3237.45754281764, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'ovr', 'n_jobs': 1, 'penalty': 'l2', 'random_state': None, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n\n13 - standardscalerwrapper\n{'module_name': 'sklearn.preprocessing._data', 'class_name': 'StandardScaler', 'copy': True, 'with_mean': False, 'with_std': False}\n\n13 - extratreesclassifier\n{'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': None, 'max_features': 0.05, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 0.01, 'min_samples_split': 0.01, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 25, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711078141770
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "capstoneModel = best_run.register_model(model_path='outputs/model.pkl', model_name='CapstoneModel_automl',\n",
        "                        tags={'Model':'Auto ML'},\n",
        "                        properties={'Accuracy': best_run_metrics['accuracy']})\n",
        "\n",
        "#capstoneModel = Model(ws, name=\"CapstoneModel_automl\")\n",
        "#model_path = capstoneModel.download(target_dir=\"./model.pkl\")\n",
        "#loaded_model = joblib.load(model_path)\n",
        "\n",
        "print(capstoneModel)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model(workspace=Workspace.create(name='udacity_ml_azure_capstone', subscription_id='a022d83d-6229-4b5e-b039-b680692436b5', resource_group='aspatton01-rg'), name=CapstoneModel_automl, id=CapstoneModel_automl:1, version=1, tags={'Model': 'Auto ML'}, properties={'Accuracy': '0.8192436974789915'})\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711078156050
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List registered models to verify if model has been saved\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CapstoneModel_automl version: 1\n\t Model : Auto ML\n\t Accuracy : 0.8192436974789915\n\n\nCapstonePenguinsModel version: 1\n\n\nHyperdrive-Capstone-Model version: 1\n\t azureml.datastoreId : /subscriptions/a022d83d-6229-4b5e-b039-b680692436b5/resourceGroups/aspatton01-rg/providers/Microsoft.MachineLearningServices/workspaces/udacity_ml_azure_capstone/datastores/workspaceartifactstore\n\n\nCapstonePenguins version: 1\n\n\nmy_model version: 1\n\n\nCapstoneBest version: 1\n\n\nhd_best_model version: 1\n\n\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711078166982
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Download scoring file \n",
        "best_run.download_file('outputs/scoring_file_v_1_0_0.py', 'score_it.py')\n",
        "\n",
        "# Download environment file\n",
        "best_run.download_file('outputs/conda_env_v_1_0_0.yml', 'envFile.yml')\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1711078239089
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.environment import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "inference_config = InferenceConfig(entry_script='score_it.py',\n",
        "                                    environment=best_run.get_environment())\n",
        "\n",
        "# deploy\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
        "service = Model.deploy(ws, \"capstone-service\", [capstoneModel], inference_config, deployment_config)\n",
        "service.wait_for_deployment(show_output = True)\n",
        "print(service.state)\n",
        "\n",
        "print(service.scoring_uri)\n",
        "\n",
        "print(service.swagger_uri)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2024-03-22 03:31:10+00:00 Creating Container Registry if not exists.\n2024-03-22 03:31:11+00:00 Use the existing image.\n2024-03-22 03:31:18+00:00 Submitting deployment to compute..\n2024-03-22 03:31:24+00:00 Checking the status of deployment capstone-service..\n2024-03-22 03:32:06+00:00 Checking the status of inference endpoint capstone-service.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\nHealthy\nhttp://4f9fd563-e1f3-4466-a1fe-53d5d552cf16.eastus2.azurecontainer.io/score\nhttp://4f9fd563-e1f3-4466-a1fe-53d5d552cf16.eastus2.azurecontainer.io/swagger.json\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711078395972
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "#Import test data\n",
        "test_df = df.sample(5) # data is the pandas dataframe of the original data\n",
        "label_df = test_df.pop('species')\n",
        "\n",
        "test_sample = json.dumps({'data': test_df.to_dict(orient='records')})\n",
        "\n",
        "print(test_sample)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\"data\": [{\"island\": \"Dream\", \"culmen_length_mm\": \"52.8\", \"culmen_depth_mm\": \"20\", \"flipper_length_mm\": \"205\", \"body_mass_g\": \"4550\", \"sex\": \"MALE\"}, {\"island\": \"Dream\", \"culmen_length_mm\": \"36.4\", \"culmen_depth_mm\": \"17\", \"flipper_length_mm\": \"195\", \"body_mass_g\": \"3325\", \"sex\": \"FEMALE\"}, {\"island\": \"Dream\", \"culmen_length_mm\": \"45.9\", \"culmen_depth_mm\": \"17.1\", \"flipper_length_mm\": \"190\", \"body_mass_g\": \"3575\", \"sex\": \"FEMALE\"}, {\"island\": \"Biscoe\", \"culmen_length_mm\": \"46.2\", \"culmen_depth_mm\": \"14.1\", \"flipper_length_mm\": \"217\", \"body_mass_g\": \"4375\", \"sex\": \"FEMALE\"}, {\"island\": \"Biscoe\", \"culmen_length_mm\": \"41.3\", \"culmen_depth_mm\": \"21.1\", \"flipper_length_mm\": \"195\", \"body_mass_g\": \"4400\", \"sex\": \"MALE\"}]}\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711078453943
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests # Used for http post request\n",
        "\n",
        "# Set the content type\n",
        "headers = {'Content-type': 'application/json'}\n",
        "\n",
        "\n",
        "response = requests.post(service.scoring_uri, test_sample, headers=headers)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711078463342
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results from the inference\n",
        "print(response.text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\"{\\\"result\\\": [\\\"Chinstrap\\\", \\\"Adelie\\\", \\\"Chinstrap\\\", \\\"Gentoo\\\", \\\"Adelie\\\"]}\"\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711078465937
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print original labels\n",
        "print(label_df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "181    Chinstrap\n34        Adelie\n166    Chinstrap\n334       Gentoo\n61        Adelie\nName: species, dtype: object\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711078470469
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2024-03-22T03:31:49,796851228+00:00 - rsyslog/run \n2024-03-22T03:31:49,803643963+00:00 - gunicorn/run \n2024-03-22T03:31:49,806844770+00:00 | gunicorn/run | \n2024-03-22T03:31:49,808664437+00:00 | gunicorn/run | ###############################################\n2024-03-22T03:31:49,810458126+00:00 | gunicorn/run | AzureML Container Runtime Information\n2024-03-22T03:31:49,816630017+00:00 | gunicorn/run | ###############################################\n2024-03-22T03:31:49,818309884+00:00 | gunicorn/run | \n2024-03-22T03:31:49,819481211+00:00 - nginx/run \n2024-03-22T03:31:49,824416775+00:00 | gunicorn/run | \n2024-03-22T03:31:49,829748140+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20230628.v2\n2024-03-22T03:31:49,830588798+00:00 | gunicorn/run | \n2024-03-22T03:31:49,831506612+00:00 | gunicorn/run | \n2024-03-22T03:31:49,832337413+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml-automl/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n2024-03-22T03:31:49,833188011+00:00 | gunicorn/run | PYTHONPATH environment variable: \n2024-03-22T03:31:49,837547342+00:00 | gunicorn/run | \n2024-03-22T03:31:50,531423526+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n\n# conda environments:\n#\n                         /azureml-envs/azureml-automl\nbase                     /opt/miniconda\n\n2024-03-22T03:31:51,375052541+00:00 | gunicorn/run | \n2024-03-22T03:31:51,376622532+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n\nadal==1.2.7\napplicationinsights==0.11.10\narch==5.3.1\nargcomplete==2.1.2\nargon2-cffi==21.3.0\nargon2-cffi-bindings==21.2.0\nasttokens==2.2.1\nattrs==23.1.0\nazure-common==1.1.28\nazure-core==1.27.1\nazure-graphrbac==0.61.1\nazure-identity==1.13.0\nazure-mgmt-authorization==3.0.0\nazure-mgmt-containerregistry==10.1.0\nazure-mgmt-core==1.4.0\nazure-mgmt-keyvault==10.2.2\nazure-mgmt-resource==22.0.0\nazure-mgmt-storage==21.0.0\nazure-storage-blob==12.13.0\nazure-storage-queue==12.6.0\nazureml-automl-core==1.52.0.post1\nazureml-automl-runtime==1.52.0.post1\nazureml-core==1.52.0\nazureml-dataprep==4.11.4\nazureml-dataprep-native==38.0.0\nazureml-dataprep-rslex==2.18.4\nazureml-dataset-runtime==1.52.0\nazureml-defaults==1.52.0\nazureml-inference-server-http==0.8.4\nazureml-interpret==1.52.0\nazureml-mlflow==1.52.0\nazureml-pipeline-core==1.52.0\nazureml-responsibleai==1.52.0\nazureml-telemetry==1.52.0\nazureml-train-automl-client==1.52.0\nazureml-train-automl-runtime==1.52.0\nazureml-train-core==1.52.0\nazureml-train-restclients-hyperdrive==1.52.0\nazureml-training-tabular==1.52.0\nbackcall==0.2.0\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\nbcrypt==4.0.1\nbeautifulsoup4==4.12.2\nbleach==6.0.0\nbokeh==2.4.3\nboto==2.49.0\nboto3==1.20.19\nbotocore==1.23.19\nBrotli @ file:///home/conda/feedstock_root/build_artifacts/brotli-split_1687884021435/work\ncachetools==5.3.1\ncertifi==2023.5.7\ncffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1671179356964/work\ncharset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1678108872112/work\nclick==8.1.4\ncloudpickle @ file:///home/conda/feedstock_root/build_artifacts/cloudpickle_1598400192773/work\ncmdstanpy==0.9.5\ncontextlib2==21.6.0\ncontourpy==1.1.0\nconvertdate @ file:///home/conda/feedstock_root/build_artifacts/convertdate_1642883757836/work\ncryptography==41.0.0\ncycler==0.11.0\nCython==0.29.17\ndask==2023.2.0\ndatabricks-cli==0.17.7\ndataclasses==0.6\ndebugpy==1.6.7\ndecorator==5.1.1\ndefusedxml==0.7.1\ndice-ml==0.9\ndill==0.3.6\ndistributed==2023.2.0\ndistro==1.8.0\ndocker==6.1.3\ndotnetcore2==3.1.23\neconml==0.14.1\nentrypoints==0.4\nephem==4.1.4\nerroranalysis==0.4.4\nexecuting==1.2.0\nfairlearn==0.8.0\nfastjsonschema==2.17.1\nfbprophet==0.7.1\nfire==0.5.0\nFlask==2.2.5\nFlask-Cors==3.0.10\nflatbuffers==23.5.26\nfonttools==4.40.0\nfsspec==2023.6.0\nfusepy==3.0.1\ngensim==3.8.3\ngitdb==4.0.10\nGitPython==3.1.31\ngoogle-api-core==2.11.1\ngoogle-auth==2.21.0\ngoogleapis-common-protos==1.59.1\ngunicorn==20.1.0\nh5py==3.9.0\nholidays @ file:///home/conda/feedstock_root/build_artifacts/holidays_1595448845196/work\nhumanfriendly==10.0\nidna @ file:///home/conda/feedstock_root/build_artifacts/idna_1663625384323/work\nimportlib-metadata==6.8.0\nimportlib-resources==5.13.0\ninference-schema==1.5.1\ninterpret-community==0.29.0\ninterpret-core==0.3.2\nipykernel==6.8.0\nipython==8.12.2\nipython-genutils==0.2.0\nisodate==0.6.1\nitsdangerous==2.1.2\njedi==0.18.2\njeepney==0.8.0\nJinja2==3.1.2\njmespath==0.10.0\njoblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1663332044897/work\njsonpickle==3.0.1\njsonschema==4.18.0\njsonschema-specifications==2023.6.1\njupyter_client==7.4.9\njupyter_core==5.3.1\njupyterlab-pygments==0.2.2\nkeras2onnx==1.6.0\nkiwisolver==1.4.4\nknack==0.10.1\nkorean-lunar-calendar @ file:///home/conda/feedstock_root/build_artifacts/korean_lunar_calendar_1663341251025/work\nlightgbm==3.2.1\nllvmlite==0.38.1\nlocket==1.0.0\nLunarCalendar==0.0.9\nMarkupSafe==2.1.2\nmatplotlib==3.7.2\nmatplotlib-inline==0.1.6\nmistune==3.0.1\nml-wrappers==0.4.11\nmlflow-skinny==2.4.1\nmltable==1.4.1\nmsal==1.22.0\nmsal-extensions==1.0.0\nmsgpack==1.0.5\nmsrest==0.7.1\nmsrestazure==0.6.4\nnbclient==0.8.0\nnbconvert==7.6.0\nnbformat==5.9.0\nndg-httpsclient==0.5.1\nnest-asyncio==1.5.6\nnetworkx==2.5\nnotebook==6.4.9\nnumba==0.55.2\nnumpy==1.22.3\noauthlib==3.2.2\nonnx==1.13.1\nonnxconverter-common==1.6.0\nonnxmltools==1.4.1\nonnxruntime==1.11.1\nopencensus==0.11.2\nopencensus-context==0.1.3\nopencensus-ext-azure==1.1.9\npackaging==23.0\npandas==1.1.5\npandocfilters==1.5.0\nparamiko==3.2.0\nparso==0.8.3\npartd==1.4.0\npathspec==0.11.1\npatsy==0.5.3\npexpect==4.8.0\npickleshare==0.7.5\nPillow==10.0.0\npkginfo==1.9.6\npkgutil_resolve_name==1.3.10\nplatformdirs @ file:///home/conda/feedstock_root/build_artifacts/platformdirs_1688739404342/work\npmdarima==1.8.0\npooch @ file:///home/conda/feedstock_root/build_artifacts/pooch_1679580333621/work\nportalocker==2.7.0\nprometheus-client==0.17.0\nprompt-toolkit==3.0.39\nproperty-cached==1.6.4\nprotobuf==3.20.3\npsutil @ file:///home/conda/feedstock_root/build_artifacts/psutil_1681775007745/work\nptyprocess==0.7.0\npure-eval==0.2.2\npy-cpuinfo==5.0.0\npyarrow==9.0.0\npyasn1==0.5.0\npyasn1-modules==0.3.0\npycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1636257122734/work\npydantic==1.10.11\nPygments==2.15.1\nPyJWT==2.7.0\nPyMeeus @ file:///home/conda/feedstock_root/build_artifacts/pymeeus_1670868433998/work\nPyNaCl==1.5.0\npyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1685514481738/work\npyparsing==3.0.9\nPySocks @ file:///home/conda/feedstock_root/build_artifacts/pysocks_1661604839144/work\npystan==2.19.1.1\npython-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\npytz @ file:///home/conda/feedstock_root/build_artifacts/pytz_1680088766131/work\nPyYAML==6.0\npyzmq==25.1.0\nraiutils==0.4.0\nreferencing==0.29.1\nrequests @ file:///home/conda/feedstock_root/build_artifacts/requests_1684774241324/work\nrequests-oauthlib==1.3.1\nresponsibleai==0.28.0\nrpds-py==0.8.8\nrsa==4.9\ns3transfer==0.5.2\nscikit-learn==0.22.1\nscipy==1.5.3\nSecretStorage==3.3.3\nsemver==2.13.0\nSend2Trash==1.8.2\nsetuptools-git==1.2\nshap==0.41.0\nsix @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\nskl2onnx==1.4.9\nsklearn-pandas==1.7.0\nslicer==0.0.7\nsmart-open==1.9.0\nsmmap==5.0.0\nsortedcontainers==2.4.0\nsoupsieve==2.4.1\nsparse==0.14.0\nsqlparse==0.4.4\nstack-data==0.6.2\nstatsmodels==0.11.1\ntabulate==0.9.0\ntblib==2.0.0\ntermcolor==2.3.0\nterminado==0.17.1\ntinycss2==1.2.1\ntoolz==0.12.0\ntornado==6.3.2\ntqdm==4.65.0\ntraitlets==5.9.0\ntyping_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1688315532570/work\nurllib3==1.26.16\nwcwidth==0.2.6\nwebencodings==0.5.1\nwebsocket-client==1.6.1\nWerkzeug==2.3.6\nwrapt==1.12.1\nxgboost==1.3.3\nzict==3.0.0\nzipp==3.15.0\n\n2024-03-22T03:31:52,833998045+00:00 | gunicorn/run | \n2024-03-22T03:31:52,835226068+00:00 | gunicorn/run | ###############################################\n2024-03-22T03:31:52,836331161+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n2024-03-22T03:31:52,837380220+00:00 | gunicorn/run | ###############################################\n2024-03-22T03:31:52,841615736+00:00 | gunicorn/run | \n2024-03-22T03:31:55,197745276+00:00 | gunicorn/run | \n2024-03-22T03:31:55,203319270+00:00 | gunicorn/run | ###############################################\n2024-03-22T03:31:55,204533502+00:00 | gunicorn/run | AzureML Inference Server\n2024-03-22T03:31:55,205911100+00:00 | gunicorn/run | ###############################################\n2024-03-22T03:31:55,207312078+00:00 | gunicorn/run | \n2024-03-22T03:31:57,550647339+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n2024-03-22 03:31:57,857 I [73] azmlinfsrv - Loaded logging config from /azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/logging.json\n2024-03-22 03:31:58,097 I [73] gunicorn.error - Starting gunicorn 20.1.0\n2024-03-22 03:31:58,097 I [73] gunicorn.error - Listening at: http://0.0.0.0:31311 (73)\n2024-03-22 03:31:58,097 I [73] gunicorn.error - Using worker: sync\n2024-03-22 03:31:58,099 I [139] gunicorn.error - Booting worker with pid: 139\n\nAzure ML Inferencing HTTP server v0.8.4\n\n/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/config.py:51: FutureWarning: aliases are no longer used by BaseSettings to define which environment variables to read. Instead use the \"env\" field setting. See https://pydantic-docs.helpmanual.io/usage/settings/#environment-variable-names\n  class AMLInferenceServerConfig(pydantic.BaseSettings):\n\nServer Settings\n---------------\nEntry Script Name: /var/azureml-app/main.py\nModel Directory: /var/azureml-app/azureml-models/CapstoneModel_automl/1\nConfig File: None\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nHealth Port: 31311\nApplication Insights Enabled: false\nApplication Insights Key: None\nInferencing HTTP server version: azmlinfsrv/0.8.4\nCORS for the specified origins: None\nCreate dedicated endpoint for health: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311/\nScore:          POST  127.0.0.1:31311/score\n\n2024-03-22 03:31:58,689 I [139] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\nInitializing logger\n2024-03-22 03:31:58,691 I [139] azmlinfsrv - Starting up app insights client\n2024-03-22 03:31:59,401 I [139] azmlinfsrv.user_script - Found driver script at /var/azureml-app/main.py and the score script at /var/azureml-app/score_it.py\n2024-03-22 03:31:59,401 I [139] azmlinfsrv.user_script - run() is decorated with @input_schema. Server will invoke it with the following arguments: data, method.\n2024-03-22 03:31:59,401 I [139] azmlinfsrv.user_script - Invoking user's init function\nERROR:fbprophet.plot:Importing plotly failed. Interactive plots will not work.\n2024-03-22 03:32:07,401 I [139] azmlinfsrv.user_script - Users's init has completed successfully\n2024-03-22 03:32:07,408 I [139] azmlinfsrv.swagger - Swaggers are prepared for the following versions: [2, 3, 3.1].\n2024-03-22 03:32:07,408 I [139] azmlinfsrv - Scoring timeout is set to 60000\n2024-03-22 03:32:27,621 I [139] gunicorn.access - 127.0.0.1 - - [22/Mar/2024:03:32:27 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"curl/7.58.0\"\n2024-03-22 03:32:59,105 I [139] gunicorn.access - 127.0.0.1 - - [22/Mar/2024:03:32:59 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"curl/7.58.0\"\n2024-03-22 03:33:09,795 W [139] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2024-03-22 03:33:09,795 I [139] gunicorn.access - 127.0.0.1 - - [22/Mar/2024:03:33:09 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2024-03-22 03:33:09,798 W [139] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2024-03-22 03:33:09,799 I [139] azmlinfsrv - GET /swagger.json 200 0.612ms 2979\n2024-03-22 03:33:09,800 I [139] gunicorn.access - 127.0.0.1 - - [22/Mar/2024:03:33:09 +0000] \"GET /swagger.json HTTP/1.0\" 200 2979 \"-\" \"Go-http-client/1.1\"\n2024-03-22 03:33:14,888 W [139] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2024-03-22 03:33:14,889 I [139] gunicorn.access - 127.0.0.1 - - [22/Mar/2024:03:33:14 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 13_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"\n2024-03-22 03:33:15,236 W [139] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2024-03-22 03:33:15,237 I [139] gunicorn.access - 127.0.0.1 - - [22/Mar/2024:03:33:15 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2024-03-22 03:33:15,813 W [139] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2024-03-22 03:33:15,814 I [139] azmlinfsrv - GET /swagger.json 200 0.383ms 2979\n2024-03-22 03:33:15,815 I [139] gunicorn.access - 127.0.0.1 - - [22/Mar/2024:03:33:15 +0000] \"GET /swagger.json HTTP/1.0\" 200 2979 \"-\" \"Go-http-client/1.1\"\n2024-03-22 03:33:20,245 W [139] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2024-03-22 03:33:20,246 I [139] gunicorn.access - 127.0.0.1 - - [22/Mar/2024:03:33:20 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2024-03-22 03:33:26,965 W [139] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2024-03-22 03:33:26,965 I [139] gunicorn.access - 127.0.0.1 - - [22/Mar/2024:03:33:26 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 13_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"\n2024-03-22 03:34:23,240 W [139] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2024-03-22 03:34:23,333 I [139] azmlinfsrv - POST /score 200 93.647ms 82\n2024-03-22 03:34:23,338 I [139] gunicorn.access - 127.0.0.1 - - [22/Mar/2024:03:34:23 +0000] \"POST /score HTTP/1.0\" 200 82 \"-\" \"python-requests/2.31.0\"\n\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711078484512
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service.delete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Running\n2024-03-22 03:36:50+00:00 Check and wait for operation (c3f18d8d-25f7-47b9-a047-16355eb845b2) to finish.\n2024-03-22 03:36:52+00:00 Deleting service entity.\nSucceeded\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1711078615899
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submission Checklist**\n",
        "- I have registered the model.\n",
        "- I have deployed the model with the best accuracy as a webservice.\n",
        "- I have tested the webservice by sending a request to the model endpoint.\n",
        "- I have deleted the webservice and shutdown all the computes that I have used.\n",
        "- I have taken a screenshot showing the model endpoint as active.\n",
        "- The project includes a file containing the environment details.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}